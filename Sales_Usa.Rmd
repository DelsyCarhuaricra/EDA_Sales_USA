---
title: "Trabajo Final de Estadística"
author: "Delsy"
date: '2022-08-20'
output: rmdformats::readthedown
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}

#AQUI SE INCLUYEN LA LISTA DE PAQUETES A INSTALAR PARA QUE FUNCIONE EL RMD  

  ifelse(require(MASS)==T, "Cargado", install.packages("readxl"))
  ifelse(require(MASS)==T, "Cargado", install.packages("MASS"))
  ifelse(require(viridis)==T, "Cargado", install.packages("viridis"))
  ifelse(require(tables)==T, "Cargado", install.packages("tables"))
  ifelse(require(Hmisc)==T, "Cargado", install.packages("Hmisc"))
  ifelse(require(flextable)==T, "Cargado", install.packages("flextable"))
  ifelse(require(dplyr)==T, "Cargado", install.packages("dplyr"))
  ifelse(require(RcmdrMisc)==T, "Cargado", install.packages("RcmdrMisc"))
  ifelse(require(webr)==T, "Cargado", install.packages("webr"))
  ifelse(require(knitr)==T, "Cargado", install.packages("knitr"))
  ifelse(require(kableExtra)==T, "Cargado", install.packages("kableExtra"))
  ifelse(require(dataMaid)==T, "Cargado", install.packages("dataMaid"))
  ifelse(require(tidylog)==T, "Cargado", install.packages("tidylog"))
  ifelse(require(stargazer)==T, "Cargado", install.packages("stargazer"))
  ifelse(require(summarytools)==T, "Cargado", install.packages("summarytools"))
  ifelse(require(metan)==T, "Cargado", install.packages("metan"))
  ifelse(require(DT)==T, "Cargado", install.packages("DT"))
  ifelse(require(expss)==T, "Cargado", install.packages("expss"))
  ifelse(require(corrplot)==T, "Cargado", install.packages("corrplot"))
  #install.packages("descr")
  #install.packages("summarytools")
  #install.packages("rriskDistributions")
  
  
#AQUI SE INCLUYEN LAS LIBRERIAS
  
  library(MASS)
  library(viridis)
  library(tables)
  library(Hmisc)
  library(kableExtra)
  library(knitr,stargazer)
  library(dataMaid,tidylog)
  library(reporttools)
  library(dplyr, warn.conflicts = FALSE)
  library(reporttools,summarytools)
  library(metan,dplyr , warn.conflicts = FALSE)
  library(flextable, DT)
  library(dplyr)
  library(RcmdrMisc)
  library(webr,expss)
  library(descr)
  library(summarytools)
  library(fitdistrplus)
  library(survival)
  library(npsurv)
  library(lsei)
  library(readr)
  library(rriskDistributions)
  library(xts)
  library(zoo)
  library(tidyverse)
  library(lubridate)
  library(tseries)
  library(astsa)
  library(forecast)
  library(foreign)
  library(timsac)
  library(vars)
  library(mFilter)
  library(dynlm)
  library(MASS)
  library(ggfortify)
  library(readxl)
  library(corrplot)
  
```


```{r include=FALSE}
L01 <- "D:/EAE Master Big Data/Estadistica/TrabajoFinal/csvlimpio/"
usaStore <- read.csv(paste(L01,"sales.csv",sep=""), header = TRUE, sep = ";")
str(usaStore)
```



```{r include=FALSE}

#Convertimos las variables cant_ordened y age a numerico

usaStore$cant_ordened <- as.numeric(usaStore$cant_ordened)

usaStore$age<- as.numeric(usaStore$age)

```


```{r include=FALSE}

sapply(usaStore, function(x) sum(is.na(x))) #Conteo de todas las columnas que tienen na

```


```{r include=FALSE}

#eliminamos los valores nulos en cant_ordened

usaStore <- usaStore[!is.na(usaStore$cant_ordened),]

```



<img
src=https://i.ibb.co/6btN7Nj/usaSales.jpg>

## Caso de Análisis

*El conjunto de datos de Ventas en línea de SalesUsa es un registro de las ventas de diferentes productos, mercancias, artefactos electrónicos en diferentes estados. Dado que una gran parte de las personas que tiene accesos a Internet se están cambiando a las compras en línea, los grandes minoristas están buscando activamente formas de aumentar sus ganancias.*

*Por esa razón presentamos los objetivos principales*


> Analizar de la cesta de la compra y encontrar la relaciones entre los articulos más relevantes

> Identificar las oportunidades de mejora en nuestro servicio de ventas en linea.

> Identifica los puntos fuertes en base al historial sistema de ventas de Sales USA. 


*Para iniciar con en análisis vamos a comenzar con la identificación de variables*


### Definición de variables


*Se cuenta con una tabla de datos de 35 variables*


Table: Definición de variables


 **N°**| **Variable** |**Descripción de la variable**|**Tipo de variable ** | 
-------| -------------|------------------------------|----------------------|
*1* |*order_id*|*Identificador de la orden* |*Cualitativa Nominal*|
*2* |*order_date*|*Fecha de la orden* |*Cuantitativa discreta*|
*3* |*status* | *Estatus del orden* |*Cualitativa ordinal*|
*4* |*item_id* | *Identificador del item* |*Calitativa Nominal*|
*5* |*sku* | *Descripción del item*   | *Cualitativa Nominal*|
*6* |*cant_ordened*|*Cantidad de items adquiridos en la orden*| *Cuantitativa Discreta*|
*7* |*price* |*Precio unitario del item*| *Cuantitativa Continua*|
*8* |*value* |*Precio general del los items adquiridos* |*Cuantitativa Continua*|
*9* |*discount_amount* | *Descuento total de los items* | *Cuantitativa Continua*|
*10* |*total* |*Precio total de los items* |*Cuantitativa Continua*|
*11* |*category* |*Categoria al cual pertenece la orden*|*Cualitativa Nominal*|
*12* |*payment_method*|*Método de pago*|*Cualitativa Nominal*|
*13* |*bi_st* |*No se tiene registro* |*Cualitativa Nominal*|
*14* |*cust_id* |*ID del cliente o customer id*| *Cualitativa Nominal*|
*15* |*year* |*Año de la compra* | *Cuantitativa discreta*|
*16* |*month* | *Mes de la compra* | *Cuantitativa discreta*|
*17* |*ref_num* |*Número de referencia* | *Cuantitativa discreta*|
*18* |*Name Prefix* | *Prefijo del nombre* | *Cualitativa ordinal*|
*19* |*First Name* | *Primer nombre* |*Cualitativa nominal*|
*20* |*Middle Initial* |*Sin detalle del campo*| *Cualitativa nominal*|
*21* |*Last Name* |*Apellido del cliente*| *Cualitativa nominal*|
*22* |*Gender* |*Genero del cliente*|*Cualitativa nominal/binaria*|
*23* |*age* |*Edad del cliente* | *Cuantitativa discreta*|
*24* |*full_name* |*Nombre completo del cliente* |*Cualitativa nominal*|
*25* |*E Mail* |*Correo electrónico del cliente* | *Cualitativa nominal*|
*26* |*Customer Since*|*Fecha de registro del cliente*| *Cuantitativa discreta*|
*27* |*SSN* | *Número de seguro social* | *Cualitativa nominal*|
*28* |*Phone No.* | *Número telefónico del cliente* | *Cualitativa nominal*|
*29* |*Place Name* | *Nombre del lugar de residencia* | *Cualitativa nominal*|
*30* |*County* | *País* | *Cualitativa nominal*|
*31* |*City* | *Ciudad* | *Cualitativa nominal*|
*32* |*State* | *Estado* | *Cualitativa nominal*|
*33* |*Zip* |*Código Postal* | *Cualitativa nominal*|
*34* |*Region* | *Región* | *Cualitativa nominal*|
*35* |*User Name* |*Nombre del usuario*| *Cualitativa nominal*|


```{r}
#Se puede eliminar la columna full name o las dos columnas previas llamadas first name and last name
#Podemos hallar un buen gráfico de la fecha de inicio de fidelización de los clientes
#
```


## **Análisis Descriptivo**

**Para el planteamiento del caso USA Store se analizará las ventas generadas ** 

**Preguntas comerciales**

* ¿Qué región/estados es la más rentable?

* ¿Qué categorías generan más ganancias en las ventas?

* ¿Cuales son los Status por ventas?

* ¿Que tipo de pago es el mas usado?

* ¿Que genero tiene mayores ventas?


### 1.- Ventas Por Región


> * ¿Qué región/estados es la más rentable?

Vamos a comenzar con el análisis filtrando las ventas por región en nuestra base de datos

```{r}
totalVentas<-aggregate(x=usaStore$total,by=list(usaStore$Region),FUN=sum)
datatable(totalVentas[order(totalVentas$x,decreasing = TRUE),])
```

> *Como podemos observar la región en donde se realizaron mayores ventas fue "South" y donde se realizaron menores ventas fue "Northeast"*

```{r }
ventasRegion <- c(0.38,0.27,0.18,0.17)
etiquetas1 <- c("South", "Midwest", "West", "Northeast")
pct1 <- round(ventasRegion/sum(ventasRegion)*100)
etiquetas1 <- paste(ventasRegion, pct1)
etiquetas1 <- paste(ventasRegion,"%",sep="")

```

```{r }

pie(ventasRegion,labels = ventasRegion,
    col=rainbow(length(etiquetas1)),
    main="Ventas por Region")

legend("topright", c("South", "Midwest", "West", "Northeast"), cex = 0.9,
       fill = rainbow(length(ventasRegion)))
```


### 2.- Ventas por Categoría de producto

Ahora lo que procederemos a conocer es:

>* ¿Qué categorías generan más ganancias en las ventas?

Para poder entender mejor cuales son las categorias de productos donde se tienen mayores ganancias recurriremos a un análisis a través de diagramas de barras


```{r }
 
#eliminamos los valores nulos en category

usaStore <- usaStore[!(usaStore$category==""),]

#Listar todas las categorias que tiene nuestra data

unique(usaStore$category) 
categoria <- usaStore$category
ventas <- usaStore$total
ventas_categoria <- data.frame(categoria,ventas)
diagramaCat_Venta <-  aggregate(x=ventas_categoria$ventas, by=list(ventas_categoria$categoria),FUN = sum)
datatable(diagramaCat_Venta[order(diagramaCat_Venta$x,decreasing = TRUE),])
diagramaCat_Venta

```

```{r }
diag_cp<- diagramaCat_Venta[order(diagramaCat_Venta$x,decreasing = TRUE),]
barplot(diag_cp$x, main ="Ventas por Categoria de producto", names.arg=c("Mobiles & Tablets","Appliances","Entertainment","Others","Computing","Women's Fashion","Men's Fashion","Beauty & Grooming","Superstore","Home & Living","Health & Sports","Kids & Baby","Soghaat","School & Education","Books"), col=rainbow(11),space =1,las=3, xlab="",  ylab="ventas",cex.names=0.5)
```


Por el diagrama podemos saber que las categorías de productos *"Mobiles & Tablets"*, *"Appliances"* y *"Entertainment"* son lo que tienen mayores ventas. Asimismo, no debemos descartar que no se tiene la categoria *"otros"*, esta se situa como la cuarta categoría mas vendida. No obstante, no podemos determinar a que productos hace referencia.

### 3.- Ventas Por Status

Ahora lo que procederemos a conocer es:

>* ¿Cuales son los Status por ventas?

Para ello vamos a realizar un diagrama de barras donde podamos mostrar cuales son los estatus más comunes de nuestro registro de ventas

```{r}

Ventas_Status <- usaStore$status

```

```{r}

Ventas_Status1 <-  aggregate(x=ventas_categoria$ventas, by=list(Ventas_Status),FUN = sum)
datatable(Ventas_Status1[order(Ventas_Status1$x,decreasing = TRUE),])

```


```{r}
diag_Status<- Ventas_Status1[order(Ventas_Status1$x,decreasing = TRUE),]
barplot(diag_Status$x, main ="Ventas por Status", names.arg=c("canceled","complete","received","order_refunded","refund","cod","paid","closed","holded","pending","processing","payment_review","pending_paypal" ), col=rainbow(11),space =1,las=3, xlab="",  ylab="ventas",cex.names=0.5)
```


Por el diagrama podemos saber que el status *"Cancelado"* , *Completado* y *"Recibido"* son los más frecuentes. Asimismo, podemos agregar que los de estatus "cancelado" representan a las ventas completamente pagadas, las "completado" aquellas que fueron completadas no obstante el pago sigue pendiente y por "order_refunded" aquellas que fueron reenbolsadas



### 4.- Ventas Por Metodo de Pago

Ahora lo que procederemos a conocer es:

> * ¿Que tipo de pago es el mas usado?

Para ello vamos a realizar un diagrama de barras donde podamos mostrar cual es el tipo de pago más común de nuestro registro de ventas

```{r }
tipoPago<-aggregate(x=usaStore$total,by=list(usaStore$payment_method), FUN=sum)
datatable(tipoPago[order(tipoPago$x,decreasing = TRUE),])
```

```{r }
diag_MedPag<- tipoPago[order(tipoPago$x,decreasing = TRUE),]
barplot(diag_MedPag$x, main ="Ventas por Medio de Pago", names.arg=c("Easypay","easypay_voucher","bankalfalah","Payaxis","cod","jazzvoucher","Easypay_MA","jazzwallet","customercredit","apg","mcblite","cashatdoorstep","financesettlement" ), col=rainbow(11),space =1,las=3, xlab="",  ylab="ventas",cex.names=0.5)
```


Interpretando el diagrama conocemos que el método de pago mas usados son *"Easypay"*,*Easypay_voucher*, *bankalfalh* y *Payaxis*.


### 5.- Ventas Por Genero

Por otro lado, queremos conocer lo siguiente:


> * ¿Que genero(hombres o mujeres) tiene mayores ventas?


Por lo tanto vamos a agrupar las ventas realizadas por hombres y mujeres y encontramos que :


```{r include = FALSE} 
totalgen <-usaStore$Gender
Venta_genero<-aggregate(x=usaStore$total,by=list(usaStore$Gender), FUN=sum)
datatable(Venta_genero[order(Venta_genero$x,decreasing = TRUE),])

```

```{r }

ventasGenero <- c(0.51,0.49)
etiquetasG <- c("Femenino", "Masculino")
pctg <- round(ventasGenero/sum(ventasGenero)*100)
etiquetasG <- paste(ventasGenero, pctg)
etiquetasG <- paste(ventasGenero,"%",sep="")

```

```{r }

pie(ventasGenero,labels = ventasGenero,
    col=rainbow(length(etiquetasG)),
    main="Ventas por Genero")

legend("topright", c("Femenino", "Masculino"), cex = 0.9,
       fill = rainbow(length(ventasGenero)))
```


##Segunda parte de analisís


Realizaremos los siguientes analisis con las 3 categorias con mayores ventas :

 - Mobiles & Tablets
 - Appliaances
 - Entertainment

```{r}

mobiletablets <- usaStore%>%group_by(total)%>%filter(category %in% c("Mobiles & Tablets"))
P_mobiletablets <- aggregate(x=mobiletablets$total,by=list(mobiletablets$sku), FUN=sum)
P_mobiletablets <- P_mobiletablets[order(P_mobiletablets$x,decreasing = TRUE),]
#Obtengo el top 10
P_mobiletables <- P_mobiletablets %>% top_n(10)
#Lo ingreso en una tabla
datatable(P_mobiletables)

```

```{r}

appliances<- usaStore%>%group_by(total)%>%filter(category %in% c("Appliances"))
appliances <- aggregate(x=appliances$total,by=list(appliances$sku), FUN=sum)
appliances <- appliances[order(appliances$x,decreasing = TRUE),]
#Obtengo el top 10
appliances <- appliances %>% top_n(10)
#Lo ingreso en una tabla
datatable(appliances)


```

```{r}
Entertainment<- usaStore%>%group_by(total)%>%filter(category %in% c("Entertainment"))
Entertainment <- aggregate(x=Entertainment$total,by=list(Entertainment$sku), FUN=sum)
Entertainment <- Entertainment[order(Entertainment$x,decreasing = TRUE),]
#Obtengo el top 10
Entertainment <- Entertainment %>% top_n(10)
#Lo ingreso en una tabla
datatable(Entertainment)
```




### Correlación



```{r}

UsaStoreCo <- select(usaStore, "cant_ordened","price","discount_amount","total","age")


#UsaStoreCo
str(UsaStoreCo)
```



```{r}
M<-cor(UsaStoreCo)
head(round(M,2))
```


```{r}

corrplot(M, method="circle")
```


#Correlación menor a cero: Si la correlación es menor a cero, significa que es negativa, es decir, que las variables se relacionan inversamente. Cuando el valor de alguna variable es alto, el valor de la otra variable es bajo. Mientras más próximo se encuentre a -1, más clara será la covariación extrema.


# Ajustes de Distribución


## Ventas según categoría

Deseo conocer cual será el pronostico de ventas de la categoría de ventas mas vendida

```{r}
#usaStore
usaStore <- usaStore[!(usaStore$category==""),]

#Por lo tanto haré un análisis de los registros de venta de las ventas de categoria "mobiles and tables"


usaStore_Tablet <- usaStore %>% filter(usaStore$category=="Mobiles & Tablets")


venta_usaStore_tablets <- usaStore_Tablet$total

#Diagrama de cullen and Frey de cantidades de ventas de tablets and mobiles


descdist(venta_usaStore_tablets, boot=1000)

```
Como se puede observar en el diagrama de cullen and frey se tiene que los ajustes de distribución que mas puede ir con el modelo son "lognormal", "weibull" y "gamma"

Vamos a validar cual de los tres puede ajustarse mas :


```{r warning=FALSE}

fit_gamma  <- fitdist(venta_usaStore_tablets/100, "gamma")
#summary(fit_gamma)

fit_lognormal <- fitdist(venta_usaStore_tablets/100, "lnorm")
#summary(fit_lognormal)

fit_weillbul <- fitdist(venta_usaStore_tablets/100, "weibull")
#summary(fit_weillbul)


par(mfrow = c(2,2))
plot.legend <- c("Weibull","lognormal","gamma")



denscomp(list(fit_weillbul,fit_lognormal,fit_gamma),legendtext = plot.legend)
qqcomp(list(fit_weillbul,fit_lognormal,fit_gamma),legendtext = plot.legend)
cdfcomp(list(fit_weillbul,fit_lognormal,fit_gamma),legendtext = plot.legend)
ppcomp(list(fit_weillbul,fit_lognormal,fit_gamma),legendtext = plot.legend)


```



Se puede observar que el ajuste de distribución que se ajusta mas es "weibull". 


+---------------------------+-------------------------+
| Tipo de distribución      | AIC obtenido            | 
+===========================+=========================+
| Gamma                     | 585890.6                |
+---------------------------+-------------------------+
| Lognormal                 | 598295.8                |
+---------------------------+-------------------------+
| Weillbul                  | 585425.9                |
+---------------------------+-------------------------+



> **Conclusión**: Teniendo en cuenta el gráfico de Cullen y Frey, el grafico de comparativas así como el criterio del menor AIC, podemos decir que la variable venta sigue una distribución weibull

En este momento, decidimos hacer una estimación de la variable ganacia total para el año siguiente de los productos de categoría "Mobiles & Tablets". Para ello, vamos a considerar una muestra de 360 días y los parámetros de la distribución log normal

Generación de la muestra:

```{r }

estimacion_venta <- rweibull(360,0.818221,3912.519211)
summary(estimacion_venta)

```
> **Conclusión**: Después de obtener la estimación y teniendo en cuenta el valor medio de la estimación se considera que la ganacia en la venta de productos de categoría  "Tablets & Mobiles" tendrá una media de "4546.152" dolares y con un máximo de "35390.53" dolares



## Ventas según tipo de Pago :



Sabemos que el tipo de pago más usado es "Easypay" por lo tanto realizaremos la estimación en base a este metodo de pago. Cual es el promedio de ingresos a recibir para los próximos 360 días 

```{r }

easypay_usaSales <- usaStore %>% filter(usaStore$payment_method=="Easypay")


summary(easypay_usaSales$total)


descdist(easypay_usaSales$total, boot=1000)

```

Como se puede observar en el diagrama de cullen and frey se tiene que los ajustes de distribución que mas puede ir con el modelo son "lognormal", "weibull" y "gamma"

Vamos a validar cual de los tres puede ajustarse mas :


```{r warning=FALSE}
#https://stackoverflow.com/questions/53557022/error-code-100-fitting-exp-distribution-using-fitdist-in-r
fit_gamma  <- fitdist((easypay_usaSales$total)/100, "gamma")
#summary(fit_gamma)

fit_lognormal <- fitdist((easypay_usaSales$total)/100, "lnorm")
#summary(fit_lognormal)

fit_weillbul <- fitdist((easypay_usaSales$total)/100, "weibull")
#summary(fit_weillbul)


par(mfrow = c(2,2))
plot.legend <- c("Weibull","lognormal","gamma")



denscomp(list(fit_weillbul,fit_lognormal,fit_gamma),legendtext = plot.legend)
qqcomp(list(fit_weillbul,fit_lognormal,fit_gamma),legendtext = plot.legend)
cdfcomp(list(fit_weillbul,fit_lognormal,fit_gamma),legendtext = plot.legend)
ppcomp(list(fit_weillbul,fit_lognormal,fit_gamma),legendtext = plot.legend)


```


Se puede observar que el ajuste de distribución que se ajusta mas es "LogNormal". 


+---------------------------+-------------------------+
| Tipo de distribución      | AIC obtenido            | 
+===========================+=========================+
| Gamma                     | 505505.8                |
+---------------------------+-------------------------+
| Lognormal                 | 492585.6                |
+---------------------------+-------------------------+
| Weillbul                  | 499721                  |
+---------------------------+-------------------------+



> **Conclusión**: Teniendo en cuenta el gráfico de Cullen y Frey, el grafico de comparativas así como el criterio del menor AIC, podemos decir que la variable venta sigue una distribución LogNormal

En este momento, decidimos hacer una estimación de la variable ganacia total para el año siguiente de los productos de categoría "Mobiles & Tablets". Para ello, vamos a considerar una muestra de 360 días y los parámetros de la distribución log normal

Generación de la muestra:

```{r }

#estimacion_weibull <- rweibull(360,0.6689953 ,1153.3599769)
#summary(estimacion_weibull)
estimacion_venta <- rlnorm(360,6.261626,1.582894)
summary(estimacion_venta)



```
> **Conclusión**: Después de obtener la estimación y teniendo en cuenta el valor medio de la estimación se considera que la ganacia en el tipo de pago "Easypay" tendrá una media de "532.1" dolares y con un máximo de "341128.53" dolares



# Regresiones lineales


```{r}
Usa <- usaStore
plot(Usa$cant_ordened,Usa$price)
```

```{r}
modelo <- lm(Usa$cant_ordened ~ Usa$price, data=Usa)
summary(modelo)
```

Al analizar este análisis los parámetros de la ecuación de la recta de mínimos cuadrados que relaciona las ventas con la ganancia, se obtiene la recta

Y=  1.45718*X +950.24669



Que la recta se ajuste a los datos no significa que el modelo sea correcto, depende del uso que queramos darle. 

Si sólo pretendemos hallar la relación entre dos variables, con calcular la recta de mínimos cuadrados es suficiente.

Si queremos verificar que tena una buena relación lineal, con el fin de inferir/ predecir con la recta de regresión debemos comprobar que se verefican unas reglas ya establecidas y acepadas que aseguran que nuestro modelo es bueno, para su verificación realizaremos los seiguientes análisis.


### Análisis de correlación

Correlación: Mide el grado de relación lineal, calculamos la matriz de coeficientes de correlación:


```{r}
cor(Usa$cant_ordened,Usa$price)
```

Esta correlación es la forma abreviada del coeficiente de correlación de Pearson, la fórmula de utilización original sería:

```{r}
cor.test(Usa$cant_ordened, Usa$price, method = "pearson")
```
 Se puede afirmar que la correlación es fuerte debido a que tiene un p-valor menor que 0.05 concretamente 2.2e-16



### Análisis de los residuos



Normalidad: Los errores deben seguir una distribución normal


```{r}
residuos <- rstandard(modelo) #Residuos estándares del modelo ajustado (Completo)
par(mfrow=c(1,3)) #Divide la ventana en una fila y tres columnas
hist(residuos) #Histograma de los resiudos estandarizados
boxplot(residuos) #Diagrama de cajas de los residuos estandarizados

qqnorm(residuos) #Gráfico de cuantiles de los residuos estandarizados

qqline(residuos)
par(mfrow=c(1,1)) #Devuelve la pantalla a su estado original

```


### Varianza constante: 
La varianza de los errores es constante

```{r}
plot(fitted.values(modelo), rstandard(modelo), xlab= "Valores ajustados", ylab= "Residuos estandarizados") # gráfico 2D de los valores ajustados vs. los residuos estandarizados 
abline(h=0) # dibuja la recta en cero 

```

Valores atípicos: La independencia de los errores 


```{r}
plot(Usa$price,rstandard(modelo),xlab="Ventas",ylab="Residuos estandarizados") 
```

### Visualización de la regresión

```{r}
plot(Usa$total, Usa$cant_ordened, xlab = "Ganancias",ylab= "ventas")
abline(modelo)
```



```{r}
plot(Usa$cant_ordened, Usa$total, xlab = "can_ordened",ylab= "Total de ventas")
abline(modelo)
```



### Análisis de regresión logística en R


Para realizar este analisis necesitamos estos requisitos: 

Variable dependiente: no métrica (dicotómica)

Variables independientes: métricas y no métricas

Según la data que se tiene no contamos con variable dicotomicas 
















